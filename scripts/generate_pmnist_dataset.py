# -*- coding: utf-8 -*-
"""Generate_PMNIST_dataset.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1s-KBSwUtT7tp280iLi8KgyHk4zThDnKD

# The MNIST dataset
We examine the format used for the MNIST dataset
"""

!pip install torch torchvision

"""# Helper files"""

def read_bytes_from_file(file_path, num_bytes, start=0, verbose=False):
    """
    Reads a specified number of bytes from a file starting at a given offset and prints them in hexadecimal.

    Parameters:
    - file_path: The path to the file.
    - num_bytes: The number of bytes to read from the file.
    - start: The offset from the beginning of the file to start reading bytes (default is 0).
    """
    with open(file_path, 'rb') as file:
        file.seek(start)  # Move to the start position
        data = file.read(num_bytes)
        if verbose:
          print("Hexadecimal representation of", num_bytes, "bytes starting from byte", start, ":")
          print(data.hex())
    return data.hex()

"""# Downloading the MNIST dataset"""

import torch
from torchvision import datasets, transforms
from torch.utils.data import DataLoader

# Define a transform to normalize the data
transform = transforms.Compose([transforms.ToTensor(),
                                transforms.Normalize((0.5,), (0.5,))])

# Download the MNIST dataset
train_set = datasets.MNIST(root='./data', download=True, train=True, transform=transform)
test_set = datasets.MNIST(root='./data', download=True, train=False, transform=transform)

# Create DataLoader for both training and test set
train_loader = DataLoader(train_set, batch_size=10, shuffle=True)
test_loader = DataLoader(test_set, batch_size=10, shuffle=False)

# Iterate through a small subset of the dataset and print the structures
for images, labels in train_loader:
    print("Batch of images shape:", images.shape)  # Expected: [batch_size, 1, 28, 28]
    print("Batch of labels shape:", labels.shape)  # Expected: [batch_size]
    break  # Only show the first batch

# Note: This code assumes you are running it in a script or interactive session where downloading datasets is permitted.

"""# List the files"""

!ls data/MNIST/raw

file_path = 'data/MNIST/raw/train-images-idx3-ubyte'
num_bytes = 16  # To read 16 bytes
start_position = 0  # Change this to read from a different start position
read_bytes_from_file(file_path, num_bytes, start_position)

"""#Examine the start of the training images file"""

!xxd -C 'data/MNIST/raw/train-images-idx3-ubyte' | head

"""#Examine the start of the training labels file"""

!xxd -C 'data/MNIST/raw/train-labels-idx1-ubyte' | head

"""# Retrieve training image file segment sanity-check"""

file_path = 'data/MNIST/raw/train-images-idx3-ubyte'
num_bytes = 16
start = 0
verbose = True
read_bytes_from_file(file_path, num_bytes, start, verbose)
# Hexadecimal representation of 16 bytes starting from byte 1 :
# 0008030000ea600000001c0000001c00
# Hexadecimal representation of 16 bytes starting from byte 0 :
# 000008030000ea600000001c0000001c

"""# Size of training file"""

! ls -last data/MNIST/raw/*ubyte

"""# Display the first training image"""

file_path = 'data/MNIST/raw/train-images-idx3-ubyte'
num_bytes = 784
start=16
verbose = False
image1 = read_bytes_from_file(file_path, num_bytes, start, verbose)
# Hexadecimal representation of 1 bytes starting from byte 15 :
# 1c
# Hexadecimal representation of 1 bytes starting from byte 16 :
# 00
len(image1)

import numpy as np

def hex_to_numpy_array(hex_data, row_length):
    """
    Converts a hexadecimal string into a numpy array of specified row length.

    Parameters:
    - hex_data: Hexadecimal string to be converted.
    - row_length: The length of each row in the resulting array.

    Returns:
    - A numpy array representing the hexadecimal data.
    """
    # Convert hex_data to bytes in decimal format
    byte_data = bytes.fromhex(hex_data)

    # Calculate the total number of expected rows
    total_bytes = len(byte_data)
    if total_bytes % row_length != 0:
        raise ValueError("The total number of bytes is not evenly divisible by the specified row length.")

    # Calculate the number of rows
    num_rows = total_bytes // row_length

    # Convert byte data to a numpy array and reshape
    np_array = np.frombuffer(byte_data, dtype=np.uint8).reshape((num_rows, row_length))

    return np_array

# Example usage (assuming read_bytes_from_file has been called and hex_data is obtained)
hex_data = image1  # This is a placeholder. Use actual hex data from read_bytes_from_file
row_length = 28  # For example, for MNIST images

try:
    image_array = hex_to_numpy_array(hex_data, row_length)
    print("Numpy array shape:", image_array.shape)
except ValueError as e:
    print(e)

"""# Display the image"""

import matplotlib.pyplot as plt

def display_image(image_array):
    """
    Displays an image from a numpy array.

    Parameters:
    - image_array: A numpy array representing the image to be displayed.
    """
    plt.imshow(image_array, cmap='gray')
    plt.colorbar()
    plt.show()

display_image(image_array)

def display_image_with_histogram(image_array):
    """
    Displays an image from a numpy array and a histogram of its pixel values.

    Parameters:
    - image_array: A numpy array representing the image to be displayed.
    """
    # Create a figure with 1 row and 2 columns of subplots
    fig, ax = plt.subplots(1, 2, figsize=(12, 6))

    # Display the image
    ax[0].imshow(image_array, cmap='gray')
    ax[0].set_title('Image')
    ax[0].axis('off')  # Hide axis ticks and labels

    # Display the histogram
    ax[1].hist(image_array.ravel(), bins=50, color='gray')
    ax[1].set_title('Pixel Value Distribution')
    ax[1].set_xlabel('Pixel Intensity')
    ax[1].set_ylabel('Frequency')

    # Show the plots
    plt.tight_layout()  # Adjust the layout to make room for the titles
    plt.show()

display_image_with_histogram(image_array)

"""# Display the second training image"""

file_path = 'data/MNIST/raw/train-images-idx3-ubyte'
num_bytes = 784
start=16+num_bytes
verbose = False
image2 = read_bytes_from_file(file_path, num_bytes, start, verbose)
hex_data = image2  # This is a placeholder. Use actual hex data from read_bytes_from_file
row_length = 28
image_array = hex_to_numpy_array(hex_data, row_length)
display_image_with_histogram(image_array)

"""# Display the 3rd digit in the MNIST training image dataset

"""

file_path = 'data/MNIST/raw/train-images-idx3-ubyte'
num_bytes = 784
start=16+num_bytes*2
verbose = False
image3 = read_bytes_from_file(file_path, num_bytes, start, verbose)
hex_data = image3  # This is a placeholder. Use actual hex data from read_bytes_from_file
row_length = 28
image_array = hex_to_numpy_array(hex_data, row_length)
display_image_with_histogram(image_array)

"""# Finding the labels"""

# Label 1
file_path = 'data/MNIST/raw/train-labels-idx1-ubyte'
num_bytes = 1
start=8 # note the offset is magic number (4 bytes) and number of labels (4 bytes)
verbose = True
label_image1 = read_bytes_from_file(file_path, num_bytes, start, verbose)
print("Label for image 1: ", label_image1)

# Label 2
start=8+1 # 2nd label
verbose = True
label_image2 = read_bytes_from_file(file_path, num_bytes, start, verbose)
print("Label for image 1: ", label_image2)
print("type(label_image2): {})".format(type(label_image2)))
print("type(int(label_image2, 16)): {})".format(type(int(label_image2, 16))))
print("int(label_image2, 16): {}".format(int(label_image2, 16)))

"""# Clone Pertubations repository"""

! git clone https://github.com/dsikar/work-in-progress.git work_in_progress

"""# Apply test perturbation"""

import sys
import os
subdirectory_path = 'work_in_progress/utils'
sys.path.append(subdirectory_path)
#!pwd # /content

from work_in_progress.utils.distance_metrics import DistanceMetric
from work_in_progress.utils.perturbations import *
from work_in_progress.utils.helper_functions import *
from work_in_progress.utils.perturbation_levels import PERTURBATION_LEVELS

# image_array
for key in PERTURBATION_LEVELS.keys():
    print("Perturbation type:", key)

# assume the repository is cloned
# git clone https://github.com/dsikar/work-in-progress.git work_in_progress
import sys
import os
subdirectory_path = 'work_in_progress/utils'
sys.path.append(subdirectory_path)

from work_in_progress.utils.perturbations import *
from work_in_progress.utils.helper_functions import *
from work_in_progress.utils.perturbation_levels import PERTURBATION_LEVELS

def random_perturbation(img):
  """
  Apply random perturbation to an image

  Parameters
  ==========
  img: numpy image array
  Returns
  ==========
  p_img: numpy array, perturbed image
  key: string, perturbation key
  level: int, perturbation level

  Notes
  ==========
  Assume repo is cloned and imports have been made outside prior to function being called
  # git clone https://github.com/dsikar/work-in-progress.git work_in_progress
  import sys
  import os
  subdirectory_path = 'work_in_progress/utils'
  sys.path.append(subdirectory_path)

  from work_in_progress.utils.perturbations import *
  from work_in_progress.utils.helper_functions import *
  from work_in_progress.utils.perturbation_levels import PERTURBATION_LEVELS
  """
  import random

  pt = Perturbation(pixel_range=(0, 255))
  key = random.choice(list(PERTURBATION_LEVELS.keys()))
  level = random.randint(0, 9)
  kwargs = PERTURBATION_LEVELS[key][k]
  p_img = getattr(pt, key)(img, **kwargs)
  # Convert the perturbed image to np.uint8 so it can be written to a binary file
  p_img_uint8 = np.array(p_img, dtype=np.uint8)
  return p_img_uint8, key, level

def find_perturbation_key_index(key_to_find):
  """
  Find the perturbation key index
  Parameters
  =========
  key_to_find: string
  Returns

  =========
  key_index: integet

  Note
  =========
  Assume repo is cloned and imports have been made outside prior to function being called
  # git clone https://github.com/dsikar/work-in-progress.git work_in_progress
  import sys
  import os
  subdirectory_path = 'work_in_progress/utils'
  sys.path.append(subdirectory_path)

  from work_in_progress.utils.perturbation_levels import PERTURBATION_LEVELS
  """
  keys_list = list(PERTURBATION_LEVELS.keys())
  key_index = keys_list.index(key_to_find)
  return key_index

def get_key_by_index(index=0, dictionary=PERTURBATION_LEVELS, ):
    """
    Retrieves the key from a dictionary given its index.

    Parameters:
    - index: The index of the key to retrieve.
    - dictionary: The dictionary from which to retrieve the key.

    Returns:
    - The key at the specified index, or None if the index is out of bounds.

    Example:
    key = get_key_by_index(1)
    print(key)
    """
    if index < 0 or index >= len(dictionary):
        return None
    return list(dictionary.keys())[index]

import random
pt = Perturbation(pixel_range=(0, 255))
# for key in PERTURBATION_LEVELS.keys():
#     print("Perturbation type:", key)
    # 2. Iterate through the perturbation parameters
    #for k in range(0, len(PERTURBATION_LEVELS[key])):
     # print(k)
# key = random.choice(list(PERTURBATION_LEVELS.keys()))
key = 'zoom_blur'
print("Randomly selected perturbation level:", key)
# k = random.randint(0, 9)
k = 6
print("Randomly selected number:", k)
kwargs = PERTURBATION_LEVELS[key][k]
tmp_img = getattr(pt, key)(image_array, **kwargs)
display_image_with_histogram(image_array)
display_image_with_histogram(tmp_img)

"""# Write the file header"""

# reset file
# !rm perturbed-train-images-idx3-ubyte
def write_custom_mnist_binary_file(filename):
    """
    Writes a binary file in the MNIST 'train-images-idx3-ubyte' format.

    Parameters:
    - filename: The name of the file to write.
    - images: A list of numpy arrays representing the images. Each array should be 28x28.
    """
    import numpy as np

    # Define the header
    magic_number = 0x00000803
    num_images = len(images)
    rows = 28
    cols = 28

    # # Ensure all images are 28x28
    # for img in images:
    #     if img.shape != (28, 28):
    #         raise ValueError("All images must be 28x28 pixels.")

    with open(filename, 'ab') as file:
        # Write the header
        file.write(magic_number.to_bytes(4, 'big'))
        file.write(num_images.to_bytes(4, 'big'))
        file.write(rows.to_bytes(4, 'big'))
        file.write(cols.to_bytes(4, 'big'))

        # # Write the image data
        # for img in images:
        #     if img.dtype != np.uint8:
        #         raise ValueError("Image data must be of type np.uint8")
        #     file.write(img.tobytes())

# Example usage
# Assuming `images` is a list of numpy arrays representing the images
# write_custom_mnist_binary_file('custom_mnist_file', images)

write_custom_mnist_binary_file('perturbed-train-images-idx3-ubyte')
# Label 1
file_path = 'perturbed-train-images-idx3-ubyte'
num_bytes = 400
start=0 # note the offset is magic number (4 bytes) and number of labels (4 bytes)
verbose = True
image1 = read_bytes_from_file(file_path, num_bytes, start, verbose)

"""# MNIST format appending functions

"""

def append_bytes_to_file(filename, value, num_bytes):
    """
    Appends a specified value as bytes to a file.

    Parameters:
    - filename: The name of the file to append the bytes to.
    - value: The integer value to be appended as bytes.
    - num_bytes: The number of bytes to represent the value.
    """
    print("num_bytes: {}".format(num_bytes))
    with open(filename, 'ab') as file:  # Open the file in append binary mode
        file.write(value.to_bytes(num_bytes, 'big'))

def append_single_image_to_file(filename, image):
    """
    Appends a single image's pixel data to the specified file.

    Parameters:
    - filename: The name of the file to append the image to.
    - image: A numpy array representing the image. The array should be 28x28 and of dtype np.uint8.
    """
    import numpy as np

    if image.shape != (28, 28):
        raise ValueError("Image must be 28x28 pixels.")
    if image.dtype != np.uint8:
        raise ValueError("Image data must be of type np.uint8")

    with open(filename, 'ab') as file:  # Open the file in append binary model
        file.write(image.tobytes())

"""# Create file header and append one image

"""

# delete file if exists
!rm perturbed-train-images-idx3-ubyte
# create the file
!touch perturbed-train-images-idx3-ubyte
# check file exists
!ls -last perturbed-train-images-idx3-ubyte

"""# Create training image file"""

# remove and create file
def create_file(filename, verbose = False):
  import os

  # Check if the file exists and remove it
  if os.path.exists(filename):
      os.remove(filename)
      if verbose:
        print(f"File {filename} has been removed.")
  else:
      if verbose:
        print(f"File {filename} does not exist.")

  # create
  with open(filename, 'a'):
      if verbose:
        print(f"File {filename} has been created or already exists.")

  # Verify creation
  if os.path.exists(filename):
      if verbose:
        print(f"Verification: File {filename} exists.")
  else:
      if verbose:
        print(f"Verification failed: File {filename} does not exist.")

######################
# Image file
######################
# # delete file if exists
# !rm perturbed-train-images-idx3-ubyte
# # create the file
# !touch perturbed-train-images-idx3-ubyte
# # check file exists
# !ls -last perturbed-train-images-idx3-ubyte
def create_mnist_data_file(image_filename, file_count):
  # image_filename = 'perturbed-train-images-idx3-ubyte'
  create_file(image_filename)

  magic_number = 0x00000803
  num_images = 120000 # Double the 60000, that is, clear plus noisy
  rows = 28
  cols = 28
  num_bytes = 4

  # magic number
  append_bytes_to_file(image_filename, magic_number, num_bytes)
  # num_images
  append_bytes_to_file(image_filename, num_images, num_bytes)
  # rows
  append_bytes_to_file(image_filename, rows, num_bytes)
  # columns
  append_bytes_to_file(image_filename, cols, num_bytes)

  # sanity check
  print("Sanity Check")
  num_bytes = 400
  start=0
  verbose = True
  read_bytes_from_file(image_filename, num_bytes, start, verbose)

# # append image
# append_single_image_to_file(filename, image_array)
# # append label
# num_bytes = 1
# # clean image
# data = 0x00
# append_bytes_to_file(image_filename, data, num_bytes)
# # append append perturbation type
# # append label
# num_bytes = 2
# # clean image
# data = 0xFFFF
# append_bytes_to_file(labels_filename, data, num_bytes)
# # append perturbed image
# append_single_image_to_file(perturbation_filename, tmp_img)

"""# Create MNIST training data file, take 2"""

def create_mnist_file(filename, header_info, verbose = False):
    """
    Writes given values to a binary file, with each value written according to its specified byte size.

    Parameters:
    - filename: The name of the file to write to.
    - values_dict: A dictionary where each key-value pair is the value to write and the number of bytes to use.

    Example:
    perturbed_train_filename = 'perturbed-train-images-idx3-ubyte'
    header_info = [
        (0x00000803, 4),  # Magic number for images, 4 bytes
        (120000, 4),      # Number of images or labels, 4 bytes
        (28, 4),         # Rows, 4 bytes (only for image files)
        (28, 4)          # Columns, 4 bytes (only for image files)
    ]

    create_mnist_file(perturbed_train_filename, header_info, verbose = True)
    """
    # reset if existing
    create_file(filename, verbose)
    for value, num_bytes in header_info:
        # file.write(value.to_bytes(num_bytes, 'big'))
        append_bytes_to_file(filename, value, num_bytes)

    # sanity check
    if verbose:
        print("Sanity Check")
        num_bytes = 400
        start=0
        #verbose = True
        read_bytes_from_file(filename, num_bytes, start, verbose)

"""# Create files
1. perturbed-train-images-idx3-ubyte
2. perturbed-train-labels-idx1-ubyte
3. perturbation-train-levels-idx0-ubyte
4. t20k-perturbed-images-idx3-ubyte
5. t20k-perturbed-labels-idx1-ubyte
6. t20k-perturbation-levels-idx0-ubyte
"""

# sanity check, magic numbers on test idx1 and idx0 files
file_path = 'data/MNIST/raw/t10k-images-idx3-ubyte'
num_bytes = 8
start=0 # note the offset is magic number (4 bytes) and number of labels (4 bytes)
verbose = True
read_bytes_from_file(file_path, num_bytes, start, verbose)
file_path = 'data/MNIST/raw/t10k-labels-idx1-ubyte'
read_bytes_from_file(file_path, num_bytes, start, verbose)

def init_perturbed_mnist_files(verbose = True):
  """
  Create the set of perturbed mnist files
  """
  # 1. perturbed-train-images-idx3-ubyte
  perturbed_train_images_idx3_ubyte  = 'perturbed-train-images-idx3-ubyte'
  header_info = [
      (0x00000803, 4),  # Magic number for images, 4 bytes
      (120000, 4),      # Number of images or labels, 4 bytes
      (28, 4),         # Rows, 4 bytes (only for image files)
      (28, 4)          # Columns, 4 bytes (only for image files)
  ]
  create_mnist_file(perturbed_train_images_idx3_ubyte, header_info, verbose)
  print("====================================")
  # 4. t20k-perturbed-images-idx3-ubyte
  t20k_perturbed_images_idx3_ubyte  = 't20k-perturbed-images-idx3-ubyte'
  header_info = [
      (0x00000803, 4),
      (20000, 4),
      (28, 4),
      (28, 4)
  ]
  create_mnist_file(t20k_perturbed_images_idx3_ubyte, header_info, verbose)
  print("====================================")
  # 2. perturbed-train-labels-idx1-ubyte
  perturbed_train_labels_idx1_ubyte  = 'perturbed-train-labels-idx1-ubyte'
  header_info = [
      (0x00000801, 4),  # Magic number for labels
      (120000, 4)
  ]
  create_mnist_file(perturbed_train_labels_idx1_ubyte, header_info, verbose)
  print("====================================")
  # 5. t20k-perturbed-labels-idx1-ubyte
  t20k_perturbed_labels_idx1_ubyte  = 't20k-perturbed-labels-idx1-ubyte'
  header_info = [
      (0x00000801, 4),
      (20000, 4)
  ]
  create_mnist_file(t20k_perturbed_labels_idx1_ubyte, header_info, verbose)
  print("====================================")
  # 3. perturbation-train-levels-idx0-ubyte
  perturbation_train_levels_idx0_ubyte  = 'perturbation-train-levels-idx0-ubyte'
  header_info = [
      (0x000007FF, 4),  # Magic number for perturbation types and intensity levels
      (120000, 4)
  ]
  create_mnist_file(perturbation_train_levels_idx0_ubyte, header_info, verbose)
  print("====================================")
  # 6. t20k-perturbation-levels-idx0-ubyte
  t20k_perturbation_levels_idx0_ubyte   = 't20k-perturbation-levels-idx0-ubyte'
  header_info = [
      (0x000007FF, 4),  # Magic number for perturbation types and intensity levels
      (20000, 4)
  ]
  create_mnist_file(t20k_perturbation_levels_idx0_ubyte, header_info, verbose)
  print("====================================")

init_perturbed_mnist_files()

"""# Display helper files"""

def display_mnist_lbl(filename, index, verbose = False):
  """
  Display the label at a given index

  Parameters
  ==========
  filename: string, the mnist binary file
  index: the index to display
  verbose: boolean, display debug info

  Example
  =========
  pmnist_lbl = 'data/MNIST/raw/train-labels-idx1-ubyte' # 'perturbed-train-labels-idx1-ubyte'
  index = 0
  verbose = True
  display_mnist_lbl(pmnist_lbl, index, verbose)
  Hexadecimal representation of 1 bytes starting from byte 8 :
  05
  In file data/MNIST/raw/train-labels-idx1-ubyte, label index 0 is 05
  """
  num_bytes = 1
  start=8+index
  verbose = True
  lbl = read_bytes_from_file(file_path, num_bytes, start, verbose)
  print("In file {}, label index {} is {}".format(filename, index, lbl))

def display_mnist_img(filename, index, verbose = False):
  """
  Display image and histogram at a given index

  Parameters
  ==========
  filename: string, the mnist binary file
  index: the index to display
  verbose: boolean, display debug info

  Example
  =========
  pmnist_img = 'data/MNIST/raw/train-images-idx3-ubyte'  # perturbed-train-images-idx3-ubyte
  index = 0
  verbose = False
  display_mnist_img(pmnist_img, index, verbose)
  """
  num_bytes = 784 #(28x28)
  start=16+(index*num_bytes)
  row_length = 28
  img_hex = read_bytes_from_file(filename, num_bytes, start, verbose)
  image_array = hex_to_numpy_array(img_hex, row_length)
  display_image_with_histogram(image_array)

def display_pmnist_perturbation(filename, index, verbose = True):
  """
  Display image perturbation and level if applicable

  Parameters
  ==========
  filename: string, the mnist binary file
  index: the index to display
  verbose: boolean, display debug info

  Example
  =========
  pmnist_perturbations = 'data/MNIST/raw/train-labels-idx1-ubyte'  # 'perturbation-train-levels-idx0-ubyte'
  index = 0
  verbose = True
  display_pmnist_perturbation(pmnist_perturbations, index, verbose)
  """
  num_bytes = 1
  key_start = 8 + (index * 2)
  level_start = 8 + (index * 2) + 1
  # POS.....8.....9.......10....11......12....13
  # HEADER..KEY0..LEVEL0..KEY1..LEVEL1..KEY2..LEVEL2
  # HEADER LENGTH = 8
  # TO RETRIEVE KEY0
  # index = 0
  # START = 8 + index (8)
  # TO RETRIEVE LEVEL0
  # START = 8 + index + 1 (9)
  # TO RETRIEVE KEY1
  # index = 1
  # START = 8 + (index*2) = 10
  # TO RETRIEVE LEVEL1
  # START = 8 + (index*2) + 1 (11)
  # TO RETRIEVE KEY2
  # index = 2
  # START = 8 + (index*2) = 12
  # TO RETRIEVE LEVEL2
  # START = 8 + (index*2) + 1 (13)
  key = read_bytes_from_file(file_path, num_bytes, key_start, verbose)
  key_index = int(key, 16)
  if key_index == 255: # 0xFF, clean image
    print("Original image, not perturbed.")
    return
  key = get_key_by_index(key_index)
  level = read_bytes_from_file(file_path, num_bytes, level_start, verbose)
  print("In file: {}, for index: {}, key index: {}, key is {}, level is {}".format(filename, index, key_index, key, level))

# pmnist_lbl = 'data/MNIST/raw/train-labels-idx1-ubyte' # 'perturbed-train-labels-idx1-ubyte'
# index = 0
# verbose = True
# display_mnist_lbl(pmnist_lbl, index, verbose)

# pmnist_img = 'data/MNIST/raw/train-images-idx3-ubyte'  # perturbed-train-images-idx3-ubyte
# index = 0
# verbose = False
# display_mnist_img(pmnist_img, index, verbose)

# pmnist_perturbations = 'data/MNIST/raw/train-labels-idx1-ubyte'  # 'perturbation-train-levels-idx0-ubyte'
# index = 0
# verbose = True
# display_pmnist_perturbation(pmnist_perturbations, index, verbose)

"""# list files"""

!ls -l *ubyte

"""# Create the perturbed MNIST training dataset - images, labels and perturbation level binary files"""

def gen_pmnist_dataset(img_path, lbl_path, pmnist_img, pmnist_lbl, pmnist_perturbations, num_files = 1, verbose = False):
  """
  Generate the PMNIST dataset

  Parameters
  ==========
  img_path: string, path to the MNIST image file
  lbl_path: string, path to the MNIST label file
  pmnist_img: string, path to the PMNIST image file
  pmnist_lbl: string, path to the PMNIST label file
  pmnist_perturbations: string, path to the PMNIST perturbation file
  num_files: int, number of files to process
  verbose: boolean, print debug info

  Note
  =========
  The maximum number of files for the training dataset is 60000, 10000 for the testing dataset

  Example
  =========
  img_path = 'data/MNIST/raw/train-images-idx3-ubyte'
  lbl_path = 'data/MNIST/raw/train-labels-idx1-ubyte'
  pmnist_img = 'perturbed-train-images-idx3-ubyte'
  pmnist_lbl = 'perturbed-train-labels-idx1-ubyte'
  pmnist_perturbations = 'perturbation-train-levels-idx0-ubyte'
  num_files = 1
  verbose = True
  gen_pmnist_dataset(img_path, lbl_path, pmnist_img, pmnist_lbl, pmnist_perturbations, num_files, verbose)
  """
  # reset files
  init_perturbed_mnist_files(verbose)

  # Number of files in the MNIST training dataset
  num_img_files = num_files # 60000

  # paths
  mnist_image_file_path = img_path # 'data/MNIST/raw/train-images-idx3-ubyte'
  mnist_label_file_path = lbl_path # 'data/MNIST/raw/train-labels-idx1-ubyte'

  # image and label data size in bytes
  num_img_bytes = 784 # (28x28)
  num_label_bytes = 1

  # header lengths
  img_header_len = 16
  label_header_len = 8

  # row x col lengths
  row_length = 28

  # The big for loop
  for i in range (0, num_img_files):
    # offsets
    img_offset = img_header_len + num_img_bytes*i
    label_offset = label_header_len + num_label_bytes*i
    # get label and image
    label = read_bytes_from_file(mnist_image_file_path, num_label_bytes, img_offset, verbose)
    # convert hex to int
    label = int(label, 16)
    img_hex = read_bytes_from_file(mnist_image_file_path, num_img_bytes, img_offset, verbose)
    # convert to array
    img_array = hex_to_numpy_array(img_hex, row_length)
    if verbose:
      # sanity check, display label and image
      print("label: {}".format(label) )
      # display original image
      display_image_with_histogram(img_array)
    # create a random perturbation
    p_img, key, level = random_perturbation(img_array)
    key_index = find_perturbation_key_index(key)
    if verbose:
      # display pertubation parameters
      print("Perturbation: {}, Perturbation index: {}, level: {}".format(key, key_index, level))
      # display perturbed image
      display_image_with_histogram(p_img)

    # Process and save image and metadata
    # 1. save the original image to perturbed image dataset
    perturbed_train_images_idx3_ubyte = pmnist_img # 'perturbed-train-images-idx3-ubyte'
    append_single_image_to_file(perturbed_train_images_idx3_ubyte, img_array)
    if verbose:
      print("Saved original image to perturbed image dataset: {}".format(perturbed_train_images_idx3_ubyte))
    # 2. save the original label to the perturbed label dataset
    perturbed_train_labels_idx1_ubyte = pmnist_lbl # 'perturbed-train-labels-idx1-ubyte'
    num_bytes = 1
    append_bytes_to_file(perturbed_train_labels_idx1_ubyte, label, num_bytes)
    if verbose:
      print("Saved original label to perturbed image dataset: {}".format(perturbed_train_labels_idx1_ubyte))
    # 3. save the perturbed image to the perturbed dataset
    append_single_image_to_file(perturbed_train_images_idx3_ubyte, p_img)
    if verbose:
      print("Saved perturbed image to perturbed image dataset: {}".format(perturbed_train_images_idx3_ubyte))
    # 4. save the original label to the perturbed label dataset (again)
    append_bytes_to_file(perturbed_train_labels_idx1_ubyte, label, num_bytes)
    if verbose:
      print("Saved original label (again) to perturbed imaged dataset: {}".format(perturbed_train_labels_idx1_ubyte))
    # 5. save the perturbation type and label for the original image to the perturbation training levels dataset
    perturbation_train_levels_idx0_ubyte = pmnist_perturbations # 'perturbation-train-levels-idx0-ubyte'
    val = 0xFFFF
    num_bytes = 2
    append_bytes_to_file(perturbation_train_levels_idx0_ubyte, val, num_bytes)
    # 6. save the perturbation type and level for the perturbed image
    num_bytes = 1
    append_bytes_to_file(perturbation_train_levels_idx0_ubyte, key_index, num_bytes)
    append_bytes_to_file(perturbation_train_levels_idx0_ubyte, level, num_bytes)

    if verbose:
      print("Processed image: ".format(i+1))

  # Sanity check
  if verbose:
    for index in range (0, num_img_files):
      # show label i
      display_mnist_lbl(pmnist_lbl, index)
      # show image i
      display_mnist_img(pmnist_img, index)
      # show perturbation i
      display_pmnist_perturbation(pmnist_perturbations, index)

# process training dataset
img_path = 'data/MNIST/raw/train-images-idx3-ubyte'
lbl_path = 'data/MNIST/raw/train-labels-idx1-ubyte'
pmnist_img = 'perturbed-train-images-idx3-ubyte'
pmnist_lbl = 'perturbed-train-labels-idx1-ubyte'
pmnist_perturbations = 'perturbation-train-levels-idx0-ubyte'
num_files = 2
verbose = True
gen_pmnist_dataset(img_path, lbl_path, pmnist_img, pmnist_lbl, pmnist_perturbations, num_files, verbose)

# process testing dataset
# TODO

"""# Debug"""

perturbed_train_labels_idx1_ubyte = ''
label = 1
num_bytes = 1

append_bytes_to_file(perturbed_train_labels_idx1_ubyte, label, num_bytes)